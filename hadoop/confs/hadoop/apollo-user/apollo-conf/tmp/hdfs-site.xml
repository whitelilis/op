<?xml version="1.0" ?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
	<property>
		<name>dfs.balance.bandwidthPerSec</name>
		<value>10485760</value>
	</property>
	<property>
		<name>dfs.block.size</name>
		<value>268435456</value>
	</property>
	<property>
		<name>dfs.client.failover.proxy.provider.adhnamenode</name>
		<value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
	</property>
	<property>
		<name>dfs.client.file-block-storage-locations.timeout.millis</name>
		<value>10000</value>
	</property>
	<property>
		<name>dfs.client.read.shortcircuit</name>
		<value>false</value>
	</property>
	<property>
		<name>dfs.datanode.balance.max.concurrent.moves</name>
		<value>24</value>
	</property>
	<property>
		<name>dfs.datanode.data.dir</name>
		<value>/data1/data,/data2/data,/data3/data,/data4/data,/data5/data,/data6/data,/data7/data,/data8/data,/data9/data,/data10/data,/data11/data,/data12/data</value>
	</property>
	<property>
		<name>dfs.datanode.directoryscan.interval</name>
		<value>3600</value>
	</property>
	<property>
		<name>dfs.datanode.directoryscan.threads</name>
		<value>10</value>
	</property>
	<property>
		<name>dfs.datanode.drop.cache.behind.reads</name>
		<value>true</value>
	</property>
	<property>
		<name>dfs.datanode.drop.cache.behind.writes</name>
		<value>true</value>
	</property>
	<property>
		<name>dfs.datanode.du.reserved</name>
		<value>21474836480</value>
	</property>
	<property>
		<name>dfs.datanode.failed.volumes.tolerated</name>
		<value>3</value>
	</property>
	<property>
		<name>dfs.datanode.handler.count</name>
		<value>40</value>
	</property>
	<property>
		<name>dfs.datanode.hdfs-blocks-metadata.enabled</name>
		<value>true</value>
	</property>
	<property>
		<name>dfs.datanode.max.transfer.threads</name>
		<value>8192</value>
	</property>
	<property>
		<name>dfs.datanode.socket.write.timeout</name>
		<value>1000000</value>
	</property>
	<property>
		<name>dfs.datanode.sync.behind.writes</name>
		<value>true</value>
	</property>
	<property>
		<name>dfs.domain.socket.path</name>
		<value>/var/run/hadoop-hdfs/dn._PORT</value>
	</property>
	<property>
		<name>dfs.ha.automatic-failover.enabled</name>
		<value>true</value>
	</property>
	<property>
		<name>dfs.ha.fencing.methods</name>
		<value>sshfence(hdfs</value>
	</property>
	<property>
		<name>dfs.ha.fencing.ssh.connect-timeout</name>
		<value>30000</value>
	</property>
	<property>
		<name>dfs.ha.fencing.ssh.private-key-files</name>
		<value>/var/lib/hadoop-hdfs/.ssh/id_rsa</value>
	</property>
	<property>
		<name>dfs.ha.namenodes.adhnamenode</name>
		<value>mainNN,backNN</value>
	</property>
	<property>
		<name>dfs.ha.zkfc.nn.http.timeout.ms</name>
		<value>0</value>
	</property>
	<property>
		<name>dfs.hosts</name>
		<value>/etc/hadoop/conf/dns</value>
	</property>
	<property>
		<name>dfs.hosts.exclude</name>
		<value>/etc/hadoop/conf/exclude-dns</value>
	</property>
	<property>
		<name>dfs.image.transfer.bandwidthPerSec</name>
		<value>52428800</value>
	</property>
	<property>
		<name>dfs.journalnode.edits.dir</name>
		<value>/data/journal</value>
	</property>
	<property>
		<name>dfs.namenode.checkpoint.txns</name>
		<value>4000000</value>
	</property>
	<property>
		<name>dfs.namenode.handler.count</name>
		<value>1024</value>
	</property>
	<property>
		<name>dfs.namenode.http-address.adhnamenode.backNN</name>
		<value>backNN.master.adh</value>
	</property>
	<property>
		<name>dfs.namenode.http-address.adhnamenode.mainNN</name>
		<value>mainNN.master.adh</value>
	</property>
	<property>
		<name>dfs.namenode.http-bind-host.adhnamenode.backNN</name>
		<value>0.0.0.0</value>
	</property>
	<property>
		<name>dfs.namenode.http-bind-host.adhnamenode.mainNN</name>
		<value>0.0.0.0</value>
	</property>
	<property>
		<name>dfs.namenode.name.dir</name>
		<value>/data1/hdfs/dfs/name</value>
	</property>
	<property>
		<name>dfs.namenode.rpc-address.adhnamenode.backNN</name>
		<value>backNN.master.adh</value>
	</property>
	<property>
		<name>dfs.namenode.rpc-address.adhnamenode.mainNN</name>
		<value>mainNN.master.adh</value>
	</property>
	<property>
		<name>dfs.namenode.rpc-bind-host.adhnamenode.backNN</name>
		<value>0.0.0.0</value>
	</property>
	<property>
		<name>dfs.namenode.rpc-bind-host.adhnamenode.mainNN</name>
		<value>0.0.0.0</value>
	</property>
	<property>
		<name>dfs.namenode.service.handler.count</name>
		<value>100</value>
	</property>
	<property>
		<name>dfs.namenode.servicerpc-bind-host.adhnamenode.backNN</name>
		<value>0.0.0.0</value>
	</property>
	<property>
		<name>dfs.namenode.servicerpc-bind-host.adhnamenode.mainNN</name>
		<value>0.0.0.0</value>
	</property>
	<property>
		<name>dfs.namenode.shared.edits.dir</name>
		<value>qjournal</value>
	</property>
	<property>
		<name>dfs.namenode.support.allow.format</name>
		<value>false</value>
	</property>
	<property>
		<name>dfs.nameservices</name>
		<value>adhnamenode</value>
	</property>
	<property>
		<name>dfs.permissions.enabled</name>
		<value>true</value>
	</property>
	<property>
		<name>dfs.permissions.superusergroup</name>
		<value>root</value>
	</property>
	<property>
		<name>dfs.replication</name>
		<value>3</value>
	</property>
	<property>
		<name>dfs.webhdfs.enabled</name>
		<value>false</value>
	</property>
	<property>
		<name>topology.script.file.name</name>
		<value>/etc/hadoop/conf/rackware</value>
	</property>
</configuration>
